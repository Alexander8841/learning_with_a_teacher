import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import OrdinalEncoder, StandardScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, roc_curve, roc_auc_score, precision_recall_curve
from sklearn.utils import shuffle
from imblearn.over_sampling import SMOTE





data = pd.read_csv('datasets/travel_insurance.csv')

## Прямое кодирование (OHE)
data_ohe = pd.get_dummies(data, dtype=int, dummy_na=True, drop_first=True)

## Разделение на выборки
features_train, features_valid, target_train, target_valid = train_test_split(
    data_ohe.drop('Claim', axis=1), 
    data_ohe['Claim'], 
    random_state=12345
)

## Стандартизация численных признаков
numeric = ['Duration', 'Net Sales', 'Commission (in value)', 'Age']

scaler = StandardScaler()
scaler.fit(features_train[numeric])
features_train[numeric] = scaler.transform(features_train[numeric])
features_valid[numeric] = scaler.transform(features_valid[numeric])
features_train;





data = pd.read_csv('datasets/travel_insurance_preprocessed.csv')
target = data['Claim']
features = data.drop('Claim', axis=1)
features_train, features_valid, target_train, target_valid = train_test_split(
    features, target, test_size=0.25, random_state=12345)

model = LogisticRegression(random_state=12345, solver='liblinear')
model.fit(features_train, target_train)
predicted_valid = model.predict(features_valid)
probablities_one_valid = model.predict_proba(features_valid)[:, 1]
roc_auc_score(target_valid, probablities_one_valid)





tpr, fpr, threshold = roc_curve(target_valid, probablities_one_valid)
plt.figure()
plt.plot([0, 1], [0, 1], linestyle='--')
plt.plot(tpr, fpr)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC-кривая')





precision, recall, thresholds = precision_recall_curve(target_valid, probablities_one_valid)
plt.figure(figsize=(6, 6))
plt.step(recall, precision, where='post')
plt.xlabel('Precision')
plt.ylim([0, 1])
plt.xlim([0, 1])
plt.title('Кривая Precision-Recall')
plt.show()





for threshold in np.arange(0, 0.3, 0.02):
    predicted_valid = probablities_one_valid > threshold
    precision = precision_score(target_valid, predicted_valid)
    recall = recall_score(target_valid, predicted_valid)
    f1 = f1_score(target_valid, predicted_valid)
    print("Порог = {:.2f} | Точность = {:.3f}, Полнота = {:.3f}, f1-мера = {:.3f}".format(
        threshold, precision, recall, f1))





def upsample(features_train, target_train, repeat):
    features_zero = features_train[target_train==0]
    features_one = features_train[target_train==1]
    target_zero = target_train[target_train==0]
    target_one = target_train[target_train==1]
    features_upsampled = pd.concat([features_zero] + [features_one] * repeat)
    target_upsampled = pd.concat([target_zero] + [target_one] * repeat)
    return shuffle(features_upsampled, target_upsampled, random_state=12345)


features_upsampled, target_upsampled = upsample(features_train, target_train, 10)

model = LogisticRegression(random_state=12345, solver='liblinear')
model.fit(features_upsampled, target_upsampled)
predicted_valid = model.predict(features_valid)
f1_score(target_valid, predicted_valid)
roc_auc_score(target_valid, model.predict_proba(features_valid)[:, 1])





smote = SMOTE(random_state=12345)
features_sm, target_sm = smote.fit_resample(features_train, target_train)

model = LogisticRegression(random_state=12345, solver='liblinear')
model.fit(features_sm, target_sm)
predicted_valid = model.predict(features_valid)
roc_auc_score(target_valid, model.predict_proba(features_valid)[:, 1])





def downsample(features_train, target_train, fraction):
    features_zero = features_train[target_train==0]
    features_one = features_train[target_train==1]
    target_zero = target_train[target_train==0]
    target_one = target_train[target_train==1]
    features_upsampled = pd.concat([features_zero.sample(frac=fraction, random_state=12345), features_one])
    target_upsampled = pd.concat([target_zero.sample(frac=fraction, random_state=12345), target_one])
    return shuffle(features_upsampled, target_upsampled, random_state=12345)


features_downsampled, target_downsampled = downsample(features_train, target_train, 0.1)

model = LogisticRegression(random_state=12345, solver='liblinear')
model.fit(features_downsampled, target_downsampled)
predicted_valid = model.predict(features_valid)
f1_score(target_valid, predicted_valid)
